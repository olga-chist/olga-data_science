"""
Medical Vector Store - –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ
"""
import os
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
import time

class MedicalVectorStore:
    def __init__(self, persist_directory="./chroma_medical_db"):
        self.persist_directory = persist_directory
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        print("üß† –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},  # –ú–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ 'cuda' –µ—Å–ª–∏ –µ—Å—Ç—å GPU
            encode_kwargs={'normalize_embeddings': True}
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        self.vectorstore = None
    
    def create_from_documents(self, documents):
        """–°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not documents:
            print("‚ùå –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return None
        
        print(f"üìö –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã
        all_texts = []
        all_metadatas = []
        
        for doc in documents:
            source = doc.get('source', 'unknown')
            doc_type = doc.get('type', 'unknown')
            
            # 2. –†–∞–∑–¥–µ–ª—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800,      # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
                chunk_overlap=100,   # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
                length_function=len,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            chunks = text_splitter.split_text(doc['text'])
            
            for i, chunk in enumerate(chunks):
                if len(chunk.strip()) > 50:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏
                    all_texts.append(chunk)
                    all_metadatas.append({
                        'source': source,
                        'type': doc_type,
                        'chunk_id': i,
                        'total_chunks': len(chunks)
                    })
        
        print(f"‚úÇÔ∏è  –°–æ–∑–¥–∞–Ω–æ {len(all_texts)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        
        if not all_texts:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã")
            return None
        
        # 3. –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
        print("‚ö° –°–æ–∑–¥–∞—é –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
        start_time = time.time()
        
        try:
            self.vectorstore = Chroma.from_texts(
                texts=all_texts,
                metadatas=all_metadatas,
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫
            self.vectorstore.persist()
            
            elapsed = time.time() - start_time
            print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ –∑–∞ {elapsed:.1f} —Å–µ–∫.")
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {self.persist_directory}")
            print(f"üìä –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(all_texts)}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã: {e}")
            return None
        
        return self.vectorstore
    
    def load_existing(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
        try:
            if os.path.exists(self.persist_directory):
                print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –∏–∑ {self.persist_directory}")
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
                count = self.vectorstore._collection.count()
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {count} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                return self.vectorstore
            else:
                print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ {self.persist_directory} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None
    
    def search(self, query, k=3):
        """–ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ"""
        if not self.vectorstore:
            print("‚ö†Ô∏è  –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É")
            return []
        
        print(f"\nüîç –ü–æ–∏—Å–∫: '{query}'")
        print("-" * 60)
        
        try:
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                print("ü§∑ –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                return []
            
            print(f"üìë –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
            
            for i, doc in enumerate(results):
                source = doc.metadata.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                content_preview = doc.page_content[:200].replace('\n', ' ')
                
                print(f"\n[{i+1}] üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {source}")
                print(f"    üìù –§—Ä–∞–≥–º–µ–Ω—Ç: {content_preview}...")
                print(f"    üìä –î–ª–∏–Ω–∞: {len(doc.page_content)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def get_stats(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        if not self.vectorstore:
            return {"status": "not_loaded"}
        
        try:
            count = self.vectorstore._collection.count()
            return {
                "status": "loaded",
                "total_chunks": count,
                "persist_directory": self.persist_directory
            }
        except:
            return {"status": "error"}