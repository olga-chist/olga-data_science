"""
CV –º–æ–¥—É–ª—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
–í–∫–ª—é—á–∞–µ—Ç:
1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–ø—É—Ö–æ–ª–µ–π –º–æ–∑–≥–∞ (MRI) - ResNet
2. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª—ë–≥–∫–∏—Ö (X-Ray) - U-Net
3. –î–µ—Ç–µ–∫—Ü–∏—è –∫–∞–º–Ω–µ–π –≤ –ø–æ—á–∫–∞—Ö (CT) - YOLOv8
"""

import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, models
import matplotlib.pyplot as plt
from pathlib import Path

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(UNet, self).__init__()
        
        # Encoder (—Å–∂–∞—Ç–∏–µ)
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        
        # Bottleneck (—Å–∞–º–æ–µ —É–∑–∫–æ–µ –º–µ—Å—Ç–æ)
        self.bottleneck = self.conv_block(512, 1024)
        
        # Decoder (—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ)
        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(1024, 512)
        
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(512, 256)
        
        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 128)
        
        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(128, 64)
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        self.out = nn.Conv2d(64, out_channels, kernel_size=1)
    
    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # Encoder
        enc1 = self.enc1(x)
        enc2 = self.enc2(F.max_pool2d(enc1, 2))
        enc3 = self.enc3(F.max_pool2d(enc2, 2))
        enc4 = self.enc4(F.max_pool2d(enc3, 2))
        
        # Bottleneck
        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))
        
        # Decoder —Å skip-connections
        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.dec4(dec4)
        
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.dec3(dec3)
        
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.dec2(dec2)
        
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.dec1(dec1)
        
        return torch.sigmoid(self.out(dec1))

class CVMedicalAssistant:
    def __init__(self):
        print("CV –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.brain_model = None
        self.lung_model = None
        self.kidney_model = None
        
         # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –¥–ª—è –ú–†–¢
        self.mri_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        # –ö–ª–∞—Å—Å—ã –¥–ª—è –ú–†–¢
        self.brain_classes = ['glioma', 'meningioma', 'pituitary', 'no_tumor']

    def load_brain_model(self, model_path, class_info_path=None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ ResNet –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ú–†–¢ –º–æ–∑–≥–∞"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å ResNet
            from torch.serialization import safe_globals
            with safe_globals([models.resnet.ResNet]):
                self.brain_model = torch.load(model_path, 
                                            map_location=self.device, 
                                            weights_only=False)
            self.brain_model.eval()
            print("‚úÖ –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ú–†–¢ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ú–†–¢: {e}")
            return False

    def load_lung_model(self, model_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ U-Net –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ª—ë–≥–∫–∏—Ö (–¢–û–õ–¨–ö–û –í–ï–°–ê)"""
        try:
          print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –ª—ë–≥–∫–∏—Ö...")
        
          # 1. –°–æ–∑–¥–∞—ë–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É UNet (–Ω–∞—à –∫–ª–∞—Å—Å)
          self.lung_model = UNet(in_channels=1, out_channels=1)
        
          # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¢–û–õ–¨–ö–û –≤–µ—Å–∞ (state_dict)
          weights_path = model_path.replace(".pth", "_weights.pth")
          print(f"   –í–µ—Å–∞ –∏–∑: {weights_path}")
          state_dict = torch.load(weights_path, map_location=self.device)
        
          # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –≤ –Ω–∞—à—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
          self.lung_model.load_state_dict(state_dict)
          self.lung_model.to(self.device)
          self.lung_model.eval()
        
          print("‚úÖ –ú–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ª—ë–≥–∫–∏—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–≤–µ—Å–∞ + –Ω–∞—à–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)")
          print(f"–ú–æ–¥–µ–ª—å –ª—ë–≥–∫–∏—Ö —Ç–∏–ø: {type(self.lung_model)}")
          print(f"–ú–æ–¥–µ–ª—å –ª—ë–≥–∫–∏—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {next(self.lung_model.parameters()).device}")
          print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in self.lung_model.parameters())}")
          return True

        except Exception as e:
          print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ª—ë–≥–∫–∏—Ö: {e}")
          return False

    def load_kidney_model(self, model_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º YOLO –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–∞–º–Ω–µ–π"""
        try:
            from ultralytics import YOLO
            self.kidney_model = YOLO(model_path)
            print("‚úÖ –ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–∞–º–Ω–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    def classify_brain_mri(self, image_path):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–ø—É—Ö–æ–ª–µ–π –º–æ–∑–≥–∞ –Ω–∞ –ú–†–¢"""
        if self.brain_model is None:
            return "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –ú–†–¢", None, None
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            from PIL import Image
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.mri_transform(image).unsqueeze(0).to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.brain_model(image_tensor)
                probs = F.softmax(outputs, dim=1)
                pred_prob, pred_class = torch.max(probs, 1)
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            diagnosis = self.brain_classes[pred_class.item()]
            confidence = pred_prob.item()
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))
            
            # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            axes[0].imshow(image)
            axes[0].set_title("–ú–†–¢ –º–æ–∑–≥–∞")
            axes[0].axis('off')
            
            # –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            y_pos = np.arange(len(self.brain_classes))
            axes[1].barh(y_pos, probs.cpu().numpy().flatten())
            axes[1].set_yticks(y_pos)
            axes[1].set_yticklabels(self.brain_classes)
            axes[1].set_xlabel("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
            axes[1].set_title(f"–î–∏–∞–≥–Ω–æ–∑: {diagnosis}\n–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")
            axes[1].invert_yaxis()
            
            plt.tight_layout()
            
            return fig, diagnosis, confidence
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ú–†–¢: {e}", None, None

    def segment_lungs(self, image_path):
        """–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª—ë–≥–∫–∏—Ö –Ω–∞ —Ä–µ–Ω—Ç–≥–µ–Ω–µ"""
        if self.lung_model is None:
        # –í–û–¢ –≠–¢–û –ò–°–ü–†–ê–í–ò–¢–¨ - –í–û–ó–í–†–ê–©–ê–¢–¨ FIGURE, –ê –ù–ï –°–¢–†–û–ö–£
          fig, ax = plt.subplots(1, 1, figsize=(8, 8))
          ax.text(0.5, 0.5, "–ú–æ–¥–µ–ª—å –ª—ë–≥–∫–∏—Ö –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞", 
                ha='center', va='center', fontsize=14)
          ax.axis('off')
          return fig, "–û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"  # ‚Üê fig –∏ —Ç–µ–∫—Å—Ç
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
            import torchvision.transforms.functional as TF
            from PIL import Image
            
            image = Image.open(image_path).convert('L')  # –í –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            image = image.resize((256, 256))
            image_tensor = TF.to_tensor(image).unsqueeze(0).to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                pred = self.lung_model(image_tensor)
                pred_binary = (pred > 0.5).float()
            
            if pred_binary is not None:
              # –°—á–∏—Ç–∞–µ–º –ø–ª–æ—â–∞–¥—å –≤ –ø–∏–∫—Å–µ–ª—è—Ö
              area_pixels = torch.sum(pred_binary > 0.5).item()
        
              # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—Å—Ç
              status_text = f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª—ë–≥–∫–∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∞. –ü–ª–æ—â–∞–¥—å: {area_pixels} px¬≤"
            else:
              status_text = "–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª—ë–≥–∫–∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"
              
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig, axes = plt.subplots(1, 3, figsize=(12, 4))
            
            img_display = image_tensor[0][0].cpu().numpy()
            pred_display = pred[0][0].cpu().numpy()
            binary_display = pred_binary[0][0].cpu().numpy()
            
            axes[0].imshow(img_display, cmap='gray')
            axes[0].set_title("–†–µ–Ω—Ç–≥–µ–Ω –ª—ë–≥–∫–∏—Ö")
            axes[0].axis('off')
            
            axes[1].imshow(pred_display, cmap='gray')
            axes[1].set_title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
            axes[1].axis('off')
            
            axes[2].imshow(binary_display, cmap='gray')
            axes[2].set_title("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
            axes[2].axis('off')
            
            plt.tight_layout()
            
            return fig, status_text
            
        except Exception as e:
            # –î–ê–ñ–ï –ü–†–ò –û–®–ò–ë–ö–ï –í–û–ó–í–†–ê–©–ê–ï–ú FIGURE
            fig, ax = plt.subplots(1, 1, figsize=(8, 8))
            ax.text(0.5, 0.5, f"–û—à–∏–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {str(e)[:100]}", 
                ha='center', va='center', fontsize=12, wrap=True)
            ax.axis('off')
            return fig, f"–û—à–∏–±–∫–∞: {e}"

    def detect_kidney_stones(self, image_path, conf_threshold=0.4):
        """–î–µ—Ç–µ–∫—Ü–∏—è –∫–∞–º–Ω–µ–π –≤ –ø–æ—á–∫–∞—Ö –Ω–∞ –ö–¢"""
        if self.kidney_model is None:
            return "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–∞–º–Ω–µ–π", 0
        
        try:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            results = self.kidney_model.predict(image_path, conf=conf_threshold)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img = cv2.imread(image_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_with_boxes = img.copy()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            stone_count = 0
            if results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes = results[0].boxes.xyxy.cpu().numpy()
                confs = results[0].boxes.conf.cpu().numpy()
                stone_count = len(boxes)
                
                # –†–∏—Å—É–µ–º —Ä–∞–º–∫–∏
                for box, conf in zip(boxes, confs):
                    x1, y1, x2, y2 = map(int, box)
                    cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    label = f"Stone {conf:.2f}"
                    cv2.putText(img_with_boxes, label, (x1, y1-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))
            
            axes[0].imshow(img)
            axes[0].set_title("–ò—Å—Ö–æ–¥–Ω–æ–µ –ö–¢")
            axes[0].axis('off')
            
            axes[1].imshow(img_with_boxes)
            axes[1].set_title(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫–∞–º–Ω–µ–π: {stone_count}")
            axes[1].axis('off')
            
            plt.tight_layout()
            
            return fig, stone_count
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}", 0

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
if __name__ == "__main__":
    assistant = CVMedicalAssistant()
    print("‚úÖ CV –º–æ–¥—É–ª—å –≥–æ—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ assistant.load_*_model() –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π.")
